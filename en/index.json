[{"categories":["RISCV"],"content":"A comparison between the implementations for the RISC-V ISA.","date":"2023-06-26","objectID":"/en/comparative-riscv/","tags":["RISCV","Implementation","Comparison"],"title":"A comparison between RISC-V implementations","uri":"/en/comparative-riscv/"},{"categories":["RISCV"],"content":"This article seeks to perform a comparison among the main implementations of RISC-V, which are the chips: Rocket, BOOM, Ariane (CVA6), and SHAKTI C-Class. ","date":"2023-06-26","objectID":"/en/comparative-riscv/:0:0","tags":["RISCV","Implementation","Comparison"],"title":"A comparison between RISC-V implementations","uri":"/en/comparative-riscv/"},{"categories":["RISCV"],"content":"Introduction RISC-V is a new Instruction Set Architecture (ISA) that originated as a research and education project at the University of California, Berkeley. It has been gaining more and more industry implementations. It was developed with the aim of being open, free, and accessible, allowing anyone to use, modify, and implement the architecture without restrictions or additional costs. The ISA was designed to support 32-bit, 64-bit, and 128-bit address spaces, aiming to enhance its adoption. This flexibility allows the RISC-V architecture to be used across a wide range of applications, from low-power devices to high-performance systems. By accommodating different word sizes, the RISC-V ISA offers greater versatility to meet the specific requirements of each project, enabling efficient utilization of available resources. This modular approach contributes to the popularity and growing acceptance of the RISC-V architecture in various industries and sectors. RISC-V is an architecture that allows individuals and organizations to create their own implementations. Due to this fact, the purpose of this article is to introduce and compare the main implementations. It consists of three sections: first, the implementations will be presented, followed by the comparison, and finally, the conclusion. ","date":"2023-06-26","objectID":"/en/comparative-riscv/:1:0","tags":["RISCV","Implementation","Comparison"],"title":"A comparison between RISC-V implementations","uri":"/en/comparative-riscv/"},{"categories":["RISCV"],"content":"Implementation For the selection of implementations to be presented, robust and advanced implementations were researched, ones capable of running an Operating System (OS) on an FPGA board. For this scenario, the following choices were made: Ariane (CVA6)[4], Boomv3[5], Rocket[1], and Shakti C-Class[2]. ","date":"2023-06-26","objectID":"/en/comparative-riscv/:2:0","tags":["RISCV","Implementation","Comparison"],"title":"A comparison between RISC-V implementations","uri":"/en/comparative-riscv/"},{"categories":["RISCV"],"content":"Rocket Chip* The Rocket Chip is a processor development project that was created at the University of California, Berkeley. It plays a significant role as an initial implementation and serves various purposes within the field of computing. The primary objective of the Rocket Chip is to act as a kind of reference model for processors based on the RISC-V Instruction Set Architecture (ISA). The Rocket Chip serves several key functions: it’s a reference for RISC-V processors, an open-source library, and a testing platform for new ideas and developments related to processors. It’s an in-order scalar processor with a 5-stage pipeline, meaning it’s a type of central processing unit in a computer. In-order refers to executing one instruction at a time, and the 5-stage pipeline refers to the steps the processor follows to execute each instruction. These steps are divided into five distinct stages: fetch (retrieve the next instruction), decode (understand what the instruction does), execute (perform the instruction’s operation), memory access (handle stored information), and write-back (update results). Pipeline Rocket Chip's pipeline It features a classic 5-stage pipeline, as described earlier. It includes a temporary storage area (cache) for data and instructions, which can be either fast or slower. The L1 and L2 cache types can be adjusted as needed. To predict where a branch (a type of decision) should go, it employs a set of configurable resources, like a crystal ball, including a Branch Target Buffer (BTB), a Branch History Table (BHT), and a Return Address Stack (RAS) – a list of places it can go back to after making a decision. Furthermore, there’s a component called the Translation Lookaside Buffer (TLB), which helps translate codes and data into information that the processor can quickly understand, ultimately aiding in making the computer run faster overall. ","date":"2023-06-26","objectID":"/en/comparative-riscv/:2:1","tags":["RISCV","Implementation","Comparison"],"title":"A comparison between RISC-V implementations","uri":"/en/comparative-riscv/"},{"categories":["RISCV"],"content":"BOOMv3 (SonicBOOM)* BOOMv3, also known as SonicBOOM, is a processor project developed by the University of California, Berkeley. It’s designed to be superscalar out-of-order, which means it can execute multiple instructions in parallel, regardless of the order they were written in the program. This typically results in high performance, as it allows the processor to make better use of available resources. The BOOMv3 pipeline consists of 10 stages, which means instructions go through a series of separate steps as they’re processed. This helps break down the work into smaller parts and increases the efficiency of the processor. However, when a branch misprediction occurs, there’s a penalty of 12 cycles, meaning the processor might need extra time to recover from an error. The BOOMv3 project is considered ambitious, as it’s intended for high-performance computing. It’s especially suitable for use in computer clusters and servers where processing power is critical. Clusters are sets of interconnected computers that work together to handle complex tasks, and servers are dedicated computers providing services like web hosting or data storage. Therefore, BOOMv3 is optimized to handle intensive workloads and is a popular choice for scenarios where performance is paramount. Pipeline BOOM's pipeline BOOM features a pipeline that can be described as complex and robust. This means it’s capable of effectively managing diverse and challenging tasks. BOOM is also configurable and customizable, allowing developers to tailor the processor according to the specific needs of their applications. An important detail is the TLB (Translation Lookaside Buffer), which helps translate codes and instructions into information that the processor can understand more quickly, enhancing overall performance. Another notable feature of BOOM is its approach to branch predictions (decisions on which path a program will follow). It employs complex two-level predictors based on global history vectors, known as GShare or TAGE. These predictors act as a kind of guessing machine that helps the processor anticipate branching decisions, improving efficiency. BOOM also supports full branch speculation. This means it can make risky decisions about paths to take and correct them if those decisions turn out to be wrong. This is accomplished using a set of resources, including the BTB (Branch Target Buffer), the BHT (Branch History Table), the TLB, and the RAS (Return Address Stack). Furthermore, there’s a component called uBTB (micro Branch Target Buffer), also known as next-line-predictor or L0 BTB. This works as a shortcut for small loops, quickly redirecting the next instruction address, which significantly enhances execution speed in specific situations. ","date":"2023-06-26","objectID":"/en/comparative-riscv/:2:2","tags":["RISCV","Implementation","Comparison"],"title":"A comparison between RISC-V implementations","uri":"/en/comparative-riscv/"},{"categories":["RISCV"],"content":"Ariane (CVA6)* CVA6 is a processor implementation developed by the HW group, a global organization dedicated to creating open-source and free hardware. This signifies that the CVA6 project is accessible to everyone, allowing individuals to study, modify, and use it as needed. It’s a superscalar out-of-order processor, which means it can execute multiple instructions simultaneously and not necessarily in the order they were written in the program. It features a 6-stage pipeline and can be compared to the Rocket Chip pipeline, which has 5 stages, but with an additional stage for the Program Counter (PC). The Program Counter is a special register that stores the address of the next instruction to be executed. In the case of CVA6, this process is treated as a separate phase in the pipeline, which can bring advantages in terms of efficiency and performance. This approach of incorporating the PC process as a pipeline stage is a distinctive feature of CVA6, potentially positively influencing the overall processor performance in certain usage scenarios. Pipeline Ariane's pipeline Ariane (CVA6) is adaptable to demand and equipped with specialized components to enhance various key tasks. One of its distinctive parts is the PTW (Page Table Walker), which acts as an intelligent translator. When an address is not found in the TLB (Translation Lookaside Buffer), the PTW comes into action. It functions as a versatile guide that queries main memory, performing the translation from virtual to physical address and subsequently adding the corresponding entry into the TLB. Its role is crucial in expediting the memory access process, optimizing information retrieval efficiency. Another notable aspect is its branch prediction capability. This prediction mechanism is supported by a set of resources, including the BTB (Branch Target Buffer), which acts as a pointer to potential choices. Additionally, the BHT (Branch History Table) functions like a diary, recording previous patterns of decisions, contributing to a more precise approach. Complementing this functionality, the TLB and the RAS (Return Address Stack) also play fundamental roles in preparing for future events, enabling more efficient and predictable processing. ","date":"2023-06-26","objectID":"/en/comparative-riscv/:2:3","tags":["RISCV","Implementation","Comparison"],"title":"A comparison between RISC-V implementations","uri":"/en/comparative-riscv/"},{"categories":["RISCV"],"content":"Shakti C-Class* SHAKTI is an open-source project initiated by the Indian Institute of Technology Madras. Its aim is to create advanced processors that are accessible and customizable for various applications. The C-Class is one of the members of the SHAKTI processor family. This processor family seeks to provide diverse options for different needs. The C-Class processor is a notable example within this family. It is an in-order scalar type and features a 5-stage pipeline. What makes it even more special is that it’s the most advanced member of the SHAKTI processor lineup. This signifies that it incorporates the latest enhancements and features developed by the project’s team. It represents the pinnacle of evolution within this processor line, ensuring enhanced performance and more sophisticated capabilities. Pipeline Shakti's pipeline Based on the implementations mentioned earlier, this processor exhibits the most essential and foundational characteristics. Its pipeline adopts a straightforward 5-stage approach, employing classic structures to optimize processing. In the realm of branch prediction, it benefits from the capabilities of BTB, BHT, and RAS, tools that work together to anticipate branching choices and optimize execution. A notable feature is that this processor has separate L1 caches, serving as temporary storage areas for frequently used data, contributing to quicker and more efficient access. Additionally, its separate associative TLBs play the role of translating virtual addresses into physical memory addresses, further optimizing overall performance. This processor stands out for its simplicity compared to the previous implementations, making it more streamlined in its operations. It is considered the most elementary among the processors mentioned earlier. Flexibility is also a key characteristic, as it can be configured and adapted according to needs, allowing specific adjustments for different scenarios. ","date":"2023-06-26","objectID":"/en/comparative-riscv/:2:4","tags":["RISCV","Implementation","Comparison"],"title":"A comparison between RISC-V implementations","uri":"/en/comparative-riscv/"},{"categories":["RISCV"],"content":"Comparison Rocket BOOMv3 Ariane C-Class Bits 32/64 64 64 32/64 Stages 5 10/12 6 5 Funct. Units 4 8 6 3 DMIPS 1,71 MHz 3,87 MHz 1,21 MHz 1,70 MHz Tech 45nm 45nm 22 nm 22 nm Speed 1,6 GHz 1,5 GHz 1,7 GHz 0,8 GHz Area 0,5 mm² 1,7 mm² 0,3 mm² 0,29 mm² Power 125 mW 300 mW 52 mW 90 mW Initially, we can observe the common characteristics between them. Both have support for 64-bit architecture. Furthermore, they implement versions close to the classic 5-stage pipeline and incorporate branch prediction in their implementations, utilizing resources like BTB, BHT, and RAS. Additionally, they are configurable, and their caches are accompanied by TLBs. Using the parameter of reported DMIPS/MHz quantity, the literature considers BOOMv3 to lead the performance criterion per MHz and surpass all others by more than a factor of 2. It’s important to note that this doesn’t necessarily mean it’s the fastest processor, but rather that it executes more instructions per clock cycle. Following in sequence, the Rocket, C-Class, and CVA6 processors follow the mentioned order. The latter achieve similar values, with the exception of Ariane. According to the chipset reference, Ariane reaches a rate of 1.70 GHz, while the literature indicates its actual rate to be 1.21 GHz, putting it at a disadvantage compared to its competitors. Thus, Ariane has the lowest rate among the compared models. BOOMv3 also stands out as the most complex implementation, with a larger silicon area and higher power consumption. This is a result of its superscalar structure, parallelism, and execution capability. However, it’s important to note that four Rocket cores could fit into a single BOOMv3 core, which applies to other implementations as well. Depending on the design, multiple low-power cores might be more advantageous than a highly efficient core. The chip technology can justify the area and consumption of these processors. Rocket and BOOMv3 are manufactured using 45 nm, while Ariane and C-Class use 22 nm. This choice of technology has a direct impact on energy consumption and the chip’s footprint. Smaller values result in lower energy requirements and greater space efficiency within the chip. With more advanced technologies, chips can be reduced in size. Another interesting point is that Ariane and C-Class manage to be smaller and consume less than half the energy of Rocket, making them ideal for projects with minimal consumption requirements. Thus, they are compact and efficient implementations. Ariane also stands out in terms of efficiency and performance. Additionally, it’s important to note that, with the exception of C-Class, all implementations present similar processing speeds. ","date":"2023-06-26","objectID":"/en/comparative-riscv/:3:0","tags":["RISCV","Implementation","Comparison"],"title":"A comparison between RISC-V implementations","uri":"/en/comparative-riscv/"},{"categories":["RISCV"],"content":"Conclusion All implementations have their advantages and disadvantages, catering to diverse audiences with specific needs. The Rocket implementation stands out for its pioneering nature, simplicity, and efficiency. Being the first implementation, it serves as the ISA debugger, shaping and referencing the emergence of new boards. Additionally, it is favored in academic publications. BOOMv3 stands out for being the most robust and efficient implementation, tailored for high-performance computing and its demands. Ariane, on the other hand, stands out for its compact size and energy efficiency. It was designed to meet more constrained development requirements. Lastly, the C-Class core is designed for medium-scale computing systems and possesses suitable characteristics for that purpose. Its approach is simple and efficient. ","date":"2023-06-26","objectID":"/en/comparative-riscv/:4:0","tags":["RISCV","Implementation","Comparison"],"title":"A comparison between RISC-V implementations","uri":"/en/comparative-riscv/"},{"categories":["RISCV"],"content":"References [1] Krste Asanović et al.2016.The Rocket Chip Generator. TechnicalReport UCB/EECS-2016-17. Department of Electrical Engineering \u0026Computer Sciences, University of California, Berkeley, CA, USA. [2] Gurajala Bhavitha Chowdary. 2022.Set Associative Data TLB for ShaktiC-Class Processor. Ph. D. Dissertation. Indian Institute of TechnologyMadras. [3] Alexander Dörflinger, Mark Albers, Benedikt Kleinbeck, Yejun Guan,Harald Michalik, Raphael Klink, Christopher Blochwitz, Anouar Nechi,and Mladen Berekovic. 2021. A comparative survey of open-sourceapplication-class RISC-V processor implementations. InProceedings ofthe 18th ACM International Conference on Computing Frontiers. ACM. https://doi.org/10.1145/3457388.3458657 [4] Florian Zaruba and Luca Benini. 2019. The Cost of Application-ClassProcessing: Energy and Performance Analysis of a Linux-Ready 1.7-GHz 64-Bit RISC-V Core in 22-nm FDSOI Technology.IEEE Transac-tions on Very Large Scale Integration (VLSI) Systems27, 11 (nov 2019),2629–2640. https://doi.org/10.1109/tvlsi.2019.2926114 [5] Jerry Zhao, Ben Korpan, Abraham Gonzalez, and Krste Asanovic. 2020.SonicBOOM: The 3rd Generation Berkeley Out-of-Order Machine.Fourth Workshop on Computer Architecture Research with RISC-V(May2020). ","date":"2023-06-26","objectID":"/en/comparative-riscv/:5:0","tags":["RISCV","Implementation","Comparison"],"title":"A comparison between RISC-V implementations","uri":"/en/comparative-riscv/"},{"categories":["RISCV"],"content":"Glossary Branch Target Buffer (BTB): Predicts the potential target address for branch instructions based on previous patterns. Translation Lookaside Buffer (TLB): It is a small associative memory that stores translations of virtual addresses to physical addresses. Cache: It is a fast storage area used to store copies of data that are frequently accessed. Page Table Walker (PTW): It is a component of a processor’s memory management unit (MMU). The PTW is responsible for translating virtual addresses into physical addresses. Return Address Stack (RAS): It is used to track the program’s execution flow and ensure that the execution flow returns appropriately to the instruction that made the call. Branch History Table (BHT): Stores patterns of branch decision history and aids in predicting the likelihood of a branch instruction being taken or not taken. ","date":"2023-06-26","objectID":"/en/comparative-riscv/:6:0","tags":["RISCV","Implementation","Comparison"],"title":"A comparison between RISC-V implementations","uri":"/en/comparative-riscv/"},{"categories":["Power Systems"],"content":"A review on IBM Power Systems.","date":"2021-12-18","objectID":"/en/review-power-architecture/","tags":["Power Systems","Power8","Power9","Power10"],"title":"IBM Power Systems - Power8, Power9 and Power10","uri":"/en/review-power-architecture/"},{"categories":["Power Systems"],"content":"This post reviews the processors that make up IBM Power Systems. ","date":"2021-12-18","objectID":"/en/review-power-architecture/:0:0","tags":["Power Systems","Power8","Power9","Power10"],"title":"IBM Power Systems - Power8, Power9 and Power10","uri":"/en/review-power-architecture/"},{"categories":["Power Systems"],"content":"Introduction In a comparison between IBM processors (Power architecture) and Intel/AMD processors (x86 architecture), it can be said that the best options between them will depend on their use. The x86 chips are intended for general use, have good scalability and high performance in almost all uses. On the other hand, Power chips are focused on using high-performance and high-performance servers. It has support to meet emerging demands, it has virtualization natively, with several hardware resources focused on virtualization, being the best possible choice for this type of work. In addition, IBM Power is focused on the business line, having support plans for different business activities. Mainly focused on virtualization solutions, to meet massive work demands. In addition, the chips have resources to share jobs or pool resources, making multiple servers behave as one. In this way, the IBM becomes a fundamental part of the business plan of any company linked to technology or that needs a great scalability of resources to meet a massive demand for work. As well as mainly for the cloud computing area. ","date":"2021-12-18","objectID":"/en/review-power-architecture/:1:0","tags":["Power Systems","Power8","Power9","Power10"],"title":"IBM Power Systems - Power8, Power9 and Power10","uri":"/en/review-power-architecture/"},{"categories":["Power Systems"],"content":"POWER8 Power8 was presented by IBM in 2014. There, IBM made several improvements over its previous version. The machines that were created with this chip, had the provision of 6 to 12 cores, in addition to a clock that varies from 2.5 GHz to 5 GHz. Power8 has 32 KB for instructions + 64 KB for data in L1 cache, 512 KB for SRAM type in L2 cache, 96 MB for eDRAM type in L3 cache and 128 MB for eDRAM type in L4 cache. Core CPU L1 cache L2 cache L3 cache L4 cache 6 to 12 2.5 GHz to 5 GHz 64 KB + 32 KB 512 KB 96 MB 128 MB When it comes to processors, memory is a fundamental resource. The cache memory is faster than the main memory (RAM memory), because of that, its size is fundamental for better processor performance. When compared to the previous version of the chip, the L3 cache memory had its size increased. This resulted in part to the higher performance of the processor compared to its predecessor. Power8 has many more features than its x86 competitors and its predecessor, being more powerful than them. In addition, it has support for simultaneous multithreading with eight cores per thread (SMT-8), having a very high degree of parallelism. ","date":"2021-12-18","objectID":"/en/review-power-architecture/:2:0","tags":["Power Systems","Power8","Power9","Power10"],"title":"IBM Power Systems - Power8, Power9 and Power10","uri":"/en/review-power-architecture/"},{"categories":["Power Systems"],"content":"POWER9 Power9 was presented by IBM in 2017. This version has improved core and hardware, the chip is smaller resulting in an optimization in energy consumption. The number of cores doubled to 24, the clock was set at 4 GHz. Power9 has 32 KB for instructions + 32 KB for data in L1 cache, 512 KB for SRAM type in L2 cache, 128 MB for eDRAM type in L3 cache. Core CPU L1 cache L2 cache L3 cache 24 4 GHz 32 KB + 32 KB 512 KB 128 MB The increase in the number of cores, plus the reduction in the size of the chip, with the increase of the L3 cache, optimizes and increases the processing power. Power9 has 1.5x better performance and 2x more memory than Power8. Power9 has a greater acceleration than its previous versions, it had optimized the reading of memories of the type DDR4. Based on the acceleration, it was possible to reduce the cycle processes, the cost of hardware and increase efficiency. The chip has been improved to have a higher bandwidth and low latency interface. This improvement was achieved through an interface created by NVIDIA, called NVLink. In addition, the architecture has also been optimized for emerging workloads. Improving your performance in carrying out work for high performance computing. All of these improvements were made with the prospect of creating a more optimized processor to develop high-performance operations, from cloud computing, to large data centers and research. ","date":"2021-12-18","objectID":"/en/review-power-architecture/:3:0","tags":["Power Systems","Power8","Power9","Power10"],"title":"IBM Power Systems - Power8, Power9 and Power10","uri":"/en/review-power-architecture/"},{"categories":["Power Systems"],"content":"POWER10 Power10 was announced by IBM in 2020, released in 2021. The chip has been enhanced for faster processing speed and greater capacity for intensive calculations. The number of cores can vary from 15 to 30, with a clock that varies from 4.5 GHz to 4 GHz. Power10 has 32 KB for instructions + 32 KB for data in the L1 cache, 2 MB type SRAM in the L2 cache, 128 MB type eDRAM in the L3 cache. Core CPU L1 cache L2 cache L3 cache 15 to 30 3.5 GHz to 4 GHz 32 KB + 32 KB 2 MB 128 MB Power10 is designed to achieve a high degree of performance in existing encryption standards and in future encryption standards. Power10 has implemented a mathematical matrix accelerator in its cores. This resulted in an AI 10x, 15x, 20x faster inference for FP32, BFloat16 and INT8 calculations, respectively, compared to Power9. Several changes have been made compared to its predecessor. Power10 had its reading hardware optimized, support for DDR5 memories was added, the L2 cache memory had its capacity increased, in addition to the chip which had its size reduced. These characteristics mean that the Power10 chip has increased performance and its optimization prepares the chip to support the newest technologies developed. IBM implemented PowerAXON on Power10. It has the ability to share the main memory of a Power10 server with other Power10 servers. This feature can be used to allow a set of small machines to become a large machine with great processing power. With all the features of previous versions optimized, with the addition of innovative features and with increased processing power and capacity, make this processor the most powerful that IBM has ever created. Perfect for data analysis jobs, cloud computing, high performance programming and among other jobs that need up-to-date and powerful machines. the OpenPower Lab does not have Power10 servers within its collection. ","date":"2021-12-18","objectID":"/en/review-power-architecture/:4:0","tags":["Power Systems","Power8","Power9","Power10"],"title":"IBM Power Systems - Power8, Power9 and Power10","uri":"/en/review-power-architecture/"},{"categories":["Tutorials"],"content":"A tutorial to minikube.","date":"2021-12-15","objectID":"/en/hello-minikube/","tags":["Tutorial","Minikube","Kubernetes"],"title":"Hello Minikube for ppc64le","uri":"/en/hello-minikube/"},{"categories":["Tutorials"],"content":"This tutorial shows you how to create a cluster for processors of the Power architecture (ppc64/ppc64le) using Minikube. The tutorial was performed on Ubuntu 20.04 LTS (ppc64le), the packages were downloaded using the package repository from OpenPower Lab @ Unicamp. ","date":"2021-12-15","objectID":"/en/hello-minikube/:0:0","tags":["Tutorial","Minikube","Kubernetes"],"title":"Hello Minikube for ppc64le","uri":"/en/hello-minikube/"},{"categories":["Tutorials"],"content":"Dependencies The following packages are required: Minikube Kubectl Docker-ce Conntrack You can use the commands below to solve the dependencies: apt-get update apt-get install docker-ce conntrack minikube kubectl It may be necessary to add the repository from OpenPower Lab @ Unicamp in your sistems. Optionally, Kubeadm and Kubelet can be installed. ","date":"2021-12-15","objectID":"/en/hello-minikube/:1:0","tags":["Tutorial","Minikube","Kubernetes"],"title":"Hello Minikube for ppc64le","uri":"/en/hello-minikube/"},{"categories":["Tutorials"],"content":"Create a minikube cluster Start Minikube sudo minikube start --driver=none The default drive is Docker, however the minikube does not recognize that Docker is available for ppc64le architecture and has an error. To make ’none’ the default drive, use the command: sudo minikube config set driver none You may need to run the command:: sudo sysctl fs.protected_regular=0 Check Status sudo minikube status Output is similar to: minikube type: Control Plane host: Running kubelet: Running apiserver: Running kubeconfig: Configured Open the Kubernetes dashboard in a browser sudo minikube dashboard ","date":"2021-12-15","objectID":"/en/hello-minikube/:2:0","tags":["Tutorial","Minikube","Kubernetes"],"title":"Hello Minikube for ppc64le","uri":"/en/hello-minikube/"},{"categories":["Tutorials"],"content":"Create a Deployment There are two structures in Kubernetes: Pod and Deployment. Pod can be a group of one or more containers, while a Deployment checks, manages and restarts the pods. That is, the deployment is recommended when it will be used in a large group of pods. Create a Deployment sudo kubectl create deployment hello-node --image=minicloud/node-server minicloud/node-server: is a public docker image created for the ppc64le architecture. The files used to build the image are in the GitHub. View the Deployment: sudo kubectl get deployments The output is similar to: NAME READY UP-TO-DATE AVAILABLE AGE hello-node 1/1 1 1 6m28s View the Pod: sudo kubectl get pods The output is similar to: NAME READY STATUS RESTARTS AGE hello-node-5dd47b76c8-l5vs2 1/1 Running 0 6m51s ","date":"2021-12-15","objectID":"/en/hello-minikube/:3:0","tags":["Tutorial","Minikube","Kubernetes"],"title":"Hello Minikube for ppc64le","uri":"/en/hello-minikube/"},{"categories":["Tutorials"],"content":"Create a Service In order to be able to directly access the Pod, it is necessary to create a service. Create a Service sudo kubectl expose deployment hello-node --type=NodePort --port=8080 View the Service sudo kubectl get services The output is similar to: NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hello-node NodePort 10.102.223.224 \u003cnone\u003e 8080:31253/TCP 8s kubernetes ClusterIP 10.96.0.1 \u003cnone\u003e 443/TCP 14m Open the service in the browser: http://localhost:8080/. If it is not possible to access this port, change the 8080, for the 5 digit port that appears in the view. In that case it would be port 31253. ","date":"2021-12-15","objectID":"/en/hello-minikube/:4:0","tags":["Tutorial","Minikube","Kubernetes"],"title":"Hello Minikube for ppc64le","uri":"/en/hello-minikube/"},{"categories":["Tutorials"],"content":"Clean up Now you can clean up the resources you created in your cluster: kubectl delete service hello-node kubectl delete deployment hello-node Optionally, stop the Minikube: minikube stop Optionally, delete the Minikube: minikube delete ","date":"2021-12-15","objectID":"/en/hello-minikube/:5:0","tags":["Tutorial","Minikube","Kubernetes"],"title":"Hello Minikube for ppc64le","uri":"/en/hello-minikube/"},{"categories":["Tutorials"],"content":"Tutorial for others architectures Hello Minikube ","date":"2021-12-15","objectID":"/en/hello-minikube/:6:0","tags":["Tutorial","Minikube","Kubernetes"],"title":"Hello Minikube for ppc64le","uri":"/en/hello-minikube/"},{"categories":null,"content":"Hi! Welcome !! My name is Junior, I am a Software Analyst at the Eldorado Institute where I work on software development for Android devices . I have a degree in Computer Science, and since I entered university in 2017, I have been contributing to the Open Source community and have a strong interest in the GNU/Linux project, computer architecture, and embedded computing. My interest in the open-source community began at the start of my undergraduate studies when I worked on porting Open Source software to the Power architecture. I also worked with OpenStack, configuring and installing a public cloud service called Minicloud . I am an Open Source enthusiast and I love to contribute to the community! All the projects I have developed and participated in are open on my GitHub . Feel free to take a look and get inspired! ","date":"2021-12-05","objectID":"/en/about/:0:0","tags":null,"title":"About Me","uri":"/en/about/"},{"categories":null,"content":"Skills OpenStack; OPNFV; CI/CD: Jenkins, TravisCi; Programming: Python, C, C++, JavaScript, Shell Script, java; Web Backend: Linux servers, Network configuration, Apache, Hugo, Django, Flask; Web Front: HTML and CSS. ","date":"2021-12-05","objectID":"/en/about/:1:0","tags":null,"title":"About Me","uri":"/en/about/"},{"categories":null,"content":"Hobbies and Interests I am love GNU/Linux; I enjoy being involved and contributing to the Open Source community ; I enjoy diving deep into and researching : Computer Architecture and Embedded Computing ; In my spare time I love to read, listen to music, play a game… I follow some mangas like: Jujutsu Kaisen, Noragami, Seraph of the end… I watch a lot of fantasy anime, like Bleach, HxH, Naruto, Sousou no Frieren, Demon Slayer… I’m an avid K-drama watcher, and I love fantasy series and movies; Whenever possible I enjoy traveling, hiking, and getting to know new places. ","date":"2021-12-05","objectID":"/en/about/:2:0","tags":null,"title":"About Me","uri":"/en/about/"}]